{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "9H3uwmDmuWkJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "TPpny0VpiGak"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import datetime as dt\n",
        "import sqlite3"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-PY0221EN-Coursera/labs/v2/exchange_rate.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2UTCsgW4iSud",
        "outputId": "42b03a7c-2916-4556-c12e-c8f3858893a2"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-08-09 06:24:38--  https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-PY0221EN-Coursera/labs/v2/exchange_rate.csv\n",
            "Resolving cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)... 169.45.118.108\n",
            "Connecting to cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)|169.45.118.108|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 45 [text/csv]\n",
            "Saving to: ‘exchange_rate.csv.1’\n",
            "\n",
            "exchange_rate.csv.1 100%[===================>]      45  --.-KB/s    in 0s      \n",
            "\n",
            "2024-08-09 06:24:38 (19.1 MB/s) - ‘exchange_rate.csv.1’ saved [45/45]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_url = \"https://web.archive.org/web/20230908091635/https://en.wikipedia.org/wiki/List_of_largest_banks\"\n",
        "\n",
        "extracted_table_attritbutes = [\"Name\", \"MC_USD_Billion\"]\n",
        "final_table_attributes = [\"Name\", \"MC_USD_Billion\", \"MC_GBP_Billion\", \"MC_EUR_Billion\", \"MC_INR_Billion\"]\n",
        "output_file_path = \"./Largest_banks_data.csv\"\n",
        "\n",
        "database_name = \"Banks.db\"\n",
        "\n",
        "table_name = \"Largest_banks\"\n",
        "log_filename = \"code_log.txt\""
      ],
      "metadata": {
        "id": "2e6TuORPicQr"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 1"
      ],
      "metadata": {
        "id": "jIlcKk7Nuai_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def log_progress(message):\n",
        "\n",
        "    ''' This function logs the mentioned message of a given stage of the\n",
        "        code execution to a log file. Function returns nothing'''\n",
        "\n",
        "    now = dt.datetime.utcnow()\n",
        "    timestamp = now.replace(microsecond=0)\n",
        "    with open(log_filename, \"a\") as f:\n",
        "      f.write(f'Timestamp: {timestamp} -----  {message}\\n')"
      ],
      "metadata": {
        "id": "NeIy-0opjOlC"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 2"
      ],
      "metadata": {
        "id": "Mfu1GeeNufQP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract(url, attribute_names):\n",
        "  ''' This function aims to extract the required\n",
        "    information from the website and save it to a data frame. The\n",
        "    function returns the data frame for further processing. '''\n",
        "\n",
        "\n",
        "  data = requests.get(url).text\n",
        "  soup = BeautifulSoup(data, \"html.parser\")\n",
        "  tables = soup.find_all(\"tbody\")\n",
        "  trs = tables[0].find_all(\"tr\")\n",
        "\n",
        "  names= []\n",
        "  mc = []\n",
        "\n",
        "  for tr in trs[1:]:\n",
        "      tds = tr.find_all(\"td\")\n",
        "      if len(tds) > 0:\n",
        "        names.append(tds[1].find_all(\"a\")[-1][\"title\"])\n",
        "        mc.append(float(tds[2].contents[0][:-1]))\n",
        "\n",
        "  df = pd.DataFrame(zip(names, mc), columns=attribute_names)\n",
        "  return df"
      ],
      "metadata": {
        "id": "_Fqg40Tokcw1"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 3"
      ],
      "metadata": {
        "id": "EAr7PYIIu1xW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def transform(dataframe, csv_filename):\n",
        "  ''' This function accesses the CSV file for exchange rate\n",
        "    information, and adds three columns to the data frame, each\n",
        "    containing the transformed version of Market Cap column to\n",
        "    respective currencies'''\n",
        "\n",
        "  exchange_df = pd.read_csv(csv_filename)\n",
        "\n",
        "  for row in exchange_df.iterrows():\n",
        "    cur = row[1].Currency\n",
        "    rate = row[1].Rate\n",
        "    dataframe[f\"MC_{cur}_Billion\"] = round(rate * dataframe[\"MC_USD_Billion\"], 2)\n",
        "\n",
        "  return dataframe"
      ],
      "metadata": {
        "id": "n7ompjaGpf3t"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 4"
      ],
      "metadata": {
        "id": "3kA9NwXWu48J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_to_csv(dataframe, output_file):\n",
        "  ''' This function saves the final data frame as a CSV file in\n",
        "    the provided path. Function returns nothing.'''\n",
        "\n",
        "  dataframe.to_csv(output_file, index=False)"
      ],
      "metadata": {
        "id": "TVM24sytrevg"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 5"
      ],
      "metadata": {
        "id": "j5i_Xn2Lu8Ih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_to_db(dataframe, db_name, table):\n",
        "  ''' This function saves the final data frame to a database\n",
        "    table with the provided name. Function returns nothing.'''\n",
        "\n",
        "\n",
        "  conn = sqlite3.connect(db_name)\n",
        "  dataframe.to_sql(table, conn, if_exists=\"replace\")\n",
        "  conn.close()"
      ],
      "metadata": {
        "id": "6snKnrb6r8hp"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 6"
      ],
      "metadata": {
        "id": "E4KSQVhFvJCJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_query(query, db_name):\n",
        "    ''' This function runs the query on the database table and\n",
        "    prints the output on the terminal. Function returns nothing. '''\n",
        "\n",
        "    conn = sqlite3.connect(db_name)\n",
        "    results = pd.read_sql(query, conn)\n",
        "    conn.close()\n",
        "    if \"index\" in results.columns:\n",
        "        results.drop([\"index\"], axis=1, inplace=True)\n",
        "    return results"
      ],
      "metadata": {
        "id": "p1TRM81JsZrK"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 7\n"
      ],
      "metadata": {
        "id": "a5KApYmxvPYI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def check_log(filename):\n",
        "  with open(filename, \"r\") as f:\n",
        "    for line in f.readlines():\n",
        "      print(line)"
      ],
      "metadata": {
        "id": "FhvK9eLTuEUz"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Execution"
      ],
      "metadata": {
        "id": "DFnyezU6wEB2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "log_progress(\"Process Started\")\n",
        "\n",
        "# Extraction\n",
        "log_progress(\"Extraction Starting\")\n",
        "df = extract(data_url, extracted_table_attritbutes)\n",
        "print(df)\n",
        "\n",
        "log_progress(\"Extraction Completed\")\n",
        "\n",
        "# Transformation\n",
        "log_progress(\"Transformation Starting\")\n",
        "\n",
        "df1 = transform(df, \"exchange_rate.csv\")\n",
        "df1 = df1[final_table_attributes]\n",
        "\n",
        "print(df1)\n",
        "\n",
        "log_progress(\"Transformation Completed\")\n",
        "\n",
        "# saving to CSV\n",
        "log_progress(\"Loading data to csv file\")\n",
        "\n",
        "load_to_csv(df1, output_file_path)\n",
        "\n",
        "log_progress(\"Data loaded to csv file\")\n",
        "\n",
        "# Saving to database\n",
        "log_progress(\"Loading data to database\")\n",
        "\n",
        "load_to_db(df1, database_name, table_name)\n",
        "\n",
        "log_progress(\"Data loaded to database\")\n",
        "\n",
        "# Run query\n",
        "log_progress(\"Running query\")\n",
        "\n",
        "query1 = \"SELECT * FROM Largest_banks\"\n",
        "result = run_query(query1, database_name)\n",
        "print(f\"Query 1: {query1}\\n{result}\")\n",
        "\n",
        "query2 = \"SELECT AVG(MC_GBP_Billion) FROM Largest_banks\"\n",
        "result = run_query(query2, database_name)\n",
        "print(f\"Query 2: {query2}\\n{result}\")\n",
        "\n",
        "\n",
        "query3 = \"SELECT Name from Largest_banks LIMIT 5\"\n",
        "result = run_query(query3, database_name)\n",
        "print(f\"Query 3: {query3}\\n{result}\")\n",
        "\n",
        "\n",
        "\n",
        "log_progress(\"Query completed\")\n",
        "\n",
        "# Check logs()\n",
        "print(\"\\n\\n\")\n",
        "check_log(log_filename)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dx1q0azrkD1m",
        "outputId": "b467908e-5c05-4153-88fa-5a753f3b7683"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                      Name  MC_USD_Billion\n",
            "0                           JPMorgan Chase          432.92\n",
            "1                          Bank of America          231.52\n",
            "2  Industrial and Commercial Bank of China          194.56\n",
            "3               Agricultural Bank of China          160.68\n",
            "4                                HDFC Bank          157.91\n",
            "5                              Wells Fargo          155.87\n",
            "6                                     HSBC          148.90\n",
            "7                           Morgan Stanley          140.83\n",
            "8                  China Construction Bank          139.82\n",
            "9                            Bank of China          136.81\n",
            "                                      Name  MC_USD_Billion  MC_GBP_Billion  \\\n",
            "0                           JPMorgan Chase          432.92          346.34   \n",
            "1                          Bank of America          231.52          185.22   \n",
            "2  Industrial and Commercial Bank of China          194.56          155.65   \n",
            "3               Agricultural Bank of China          160.68          128.54   \n",
            "4                                HDFC Bank          157.91          126.33   \n",
            "5                              Wells Fargo          155.87          124.70   \n",
            "6                                     HSBC          148.90          119.12   \n",
            "7                           Morgan Stanley          140.83          112.66   \n",
            "8                  China Construction Bank          139.82          111.86   \n",
            "9                            Bank of China          136.81          109.45   \n",
            "\n",
            "   MC_EUR_Billion  MC_INR_Billion  \n",
            "0          402.62        35910.71  \n",
            "1          215.31        19204.58  \n",
            "2          180.94        16138.75  \n",
            "3          149.43        13328.41  \n",
            "4          146.86        13098.63  \n",
            "5          144.96        12929.42  \n",
            "6          138.48        12351.26  \n",
            "7          130.97        11681.85  \n",
            "8          130.03        11598.07  \n",
            "9          127.23        11348.39  \n",
            "Query 1: SELECT * FROM Largest_banks\n",
            "                                      Name  MC_USD_Billion  MC_GBP_Billion  \\\n",
            "0                           JPMorgan Chase          432.92          346.34   \n",
            "1                          Bank of America          231.52          185.22   \n",
            "2  Industrial and Commercial Bank of China          194.56          155.65   \n",
            "3               Agricultural Bank of China          160.68          128.54   \n",
            "4                                HDFC Bank          157.91          126.33   \n",
            "5                              Wells Fargo          155.87          124.70   \n",
            "6                                     HSBC          148.90          119.12   \n",
            "7                           Morgan Stanley          140.83          112.66   \n",
            "8                  China Construction Bank          139.82          111.86   \n",
            "9                            Bank of China          136.81          109.45   \n",
            "\n",
            "   MC_EUR_Billion  MC_INR_Billion  \n",
            "0          402.62        35910.71  \n",
            "1          215.31        19204.58  \n",
            "2          180.94        16138.75  \n",
            "3          149.43        13328.41  \n",
            "4          146.86        13098.63  \n",
            "5          144.96        12929.42  \n",
            "6          138.48        12351.26  \n",
            "7          130.97        11681.85  \n",
            "8          130.03        11598.07  \n",
            "9          127.23        11348.39  \n",
            "Query 2: SELECT AVG(MC_GBP_Billion) FROM Largest_banks\n",
            "   AVG(MC_GBP_Billion)\n",
            "0              151.987\n",
            "Query 3: SELECT Name from Largest_banks LIMIT 5\n",
            "                                      Name\n",
            "0                           JPMorgan Chase\n",
            "1                          Bank of America\n",
            "2  Industrial and Commercial Bank of China\n",
            "3               Agricultural Bank of China\n",
            "4                                HDFC Bank\n",
            "\n",
            "\n",
            "\n",
            "Timestamp: 2024-08-09 06:23:07 -----  Process Started\n",
            "\n",
            "Timestamp: 2024-08-09 06:23:07 -----  Extraction Starting\n",
            "\n",
            "Timestamp: 2024-08-09 06:23:08 -----  Extraction Completed\n",
            "\n",
            "Timestamp: 2024-08-09 06:23:08 -----  Transformation Starting\n",
            "\n",
            "Timestamp: 2024-08-09 06:23:08 -----  Transformation Completed\n",
            "\n",
            "Timestamp: 2024-08-09 06:23:08 -----  Loading data to csv file\n",
            "\n",
            "Timestamp: 2024-08-09 06:23:08 -----  Data loaded to csv file\n",
            "\n",
            "Timestamp: 2024-08-09 06:23:08 -----  Loading data to database\n",
            "\n",
            "Timestamp: 2024-08-09 06:23:08 -----  Data loaded to database\n",
            "\n",
            "Timestamp: 2024-08-09 06:23:08 -----  Running query\n",
            "\n",
            "Timestamp: 2024-08-09 06:23:08 -----  Query completed\n",
            "\n",
            "Timestamp: 2024-08-09 06:24:38 -----  Process Started\n",
            "\n",
            "Timestamp: 2024-08-09 06:24:38 -----  Extraction Starting\n",
            "\n",
            "Timestamp: 2024-08-09 06:24:39 -----  Extraction Completed\n",
            "\n",
            "Timestamp: 2024-08-09 06:24:39 -----  Transformation Starting\n",
            "\n",
            "Timestamp: 2024-08-09 06:24:39 -----  Transformation Completed\n",
            "\n",
            "Timestamp: 2024-08-09 06:24:39 -----  Loading data to csv file\n",
            "\n",
            "Timestamp: 2024-08-09 06:24:39 -----  Data loaded to csv file\n",
            "\n",
            "Timestamp: 2024-08-09 06:24:39 -----  Loading data to database\n",
            "\n",
            "Timestamp: 2024-08-09 06:24:39 -----  Data loaded to database\n",
            "\n",
            "Timestamp: 2024-08-09 06:24:39 -----  Running query\n",
            "\n",
            "Timestamp: 2024-08-09 06:24:39 -----  Query completed\n",
            "\n",
            "Timestamp: 2024-08-09 06:33:49 -----  Process Started\n",
            "\n",
            "Timestamp: 2024-08-09 06:33:49 -----  Extraction Starting\n",
            "\n",
            "Timestamp: 2024-08-09 06:33:50 -----  Extraction Completed\n",
            "\n",
            "Timestamp: 2024-08-09 06:33:50 -----  Transformation Starting\n",
            "\n",
            "Timestamp: 2024-08-09 06:33:50 -----  Transformation Completed\n",
            "\n",
            "Timestamp: 2024-08-09 06:33:50 -----  Loading data to csv file\n",
            "\n",
            "Timestamp: 2024-08-09 06:33:50 -----  Data loaded to csv file\n",
            "\n",
            "Timestamp: 2024-08-09 06:33:50 -----  Loading data to database\n",
            "\n",
            "Timestamp: 2024-08-09 06:33:50 -----  Data loaded to database\n",
            "\n",
            "Timestamp: 2024-08-09 06:33:50 -----  Running query\n",
            "\n",
            "Timestamp: 2024-08-09 06:34:33 -----  Process Started\n",
            "\n",
            "Timestamp: 2024-08-09 06:34:33 -----  Extraction Starting\n",
            "\n",
            "Timestamp: 2024-08-09 06:34:33 -----  Extraction Completed\n",
            "\n",
            "Timestamp: 2024-08-09 06:34:33 -----  Transformation Starting\n",
            "\n",
            "Timestamp: 2024-08-09 06:34:33 -----  Transformation Completed\n",
            "\n",
            "Timestamp: 2024-08-09 06:34:33 -----  Loading data to csv file\n",
            "\n",
            "Timestamp: 2024-08-09 06:34:33 -----  Data loaded to csv file\n",
            "\n",
            "Timestamp: 2024-08-09 06:34:33 -----  Loading data to database\n",
            "\n",
            "Timestamp: 2024-08-09 06:34:33 -----  Data loaded to database\n",
            "\n",
            "Timestamp: 2024-08-09 06:34:33 -----  Running query\n",
            "\n",
            "Timestamp: 2024-08-09 06:34:33 -----  Query completed\n",
            "\n",
            "Timestamp: 2024-08-09 06:36:26 -----  Process Started\n",
            "\n",
            "Timestamp: 2024-08-09 06:36:26 -----  Extraction Starting\n",
            "\n",
            "Timestamp: 2024-08-09 06:36:27 -----  Extraction Completed\n",
            "\n",
            "Timestamp: 2024-08-09 06:36:27 -----  Transformation Starting\n",
            "\n",
            "Timestamp: 2024-08-09 06:36:27 -----  Transformation Completed\n",
            "\n",
            "Timestamp: 2024-08-09 06:36:27 -----  Loading data to csv file\n",
            "\n",
            "Timestamp: 2024-08-09 06:36:27 -----  Data loaded to csv file\n",
            "\n",
            "Timestamp: 2024-08-09 06:36:27 -----  Loading data to database\n",
            "\n",
            "Timestamp: 2024-08-09 06:36:27 -----  Data loaded to database\n",
            "\n",
            "Timestamp: 2024-08-09 06:36:27 -----  Running query\n",
            "\n",
            "Timestamp: 2024-08-09 06:36:27 -----  Query completed\n",
            "\n",
            "Timestamp: 2024-08-09 06:40:22 -----  Process Started\n",
            "\n",
            "Timestamp: 2024-08-09 06:40:22 -----  Extraction Starting\n",
            "\n",
            "Timestamp: 2024-08-09 06:40:23 -----  Extraction Completed\n",
            "\n",
            "Timestamp: 2024-08-09 06:40:23 -----  Transformation Starting\n",
            "\n",
            "Timestamp: 2024-08-09 06:40:23 -----  Transformation Completed\n",
            "\n",
            "Timestamp: 2024-08-09 06:40:23 -----  Loading data to csv file\n",
            "\n",
            "Timestamp: 2024-08-09 06:40:23 -----  Data loaded to csv file\n",
            "\n",
            "Timestamp: 2024-08-09 06:40:23 -----  Loading data to database\n",
            "\n",
            "Timestamp: 2024-08-09 06:40:23 -----  Data loaded to database\n",
            "\n",
            "Timestamp: 2024-08-09 06:40:23 -----  Running query\n",
            "\n",
            "Timestamp: 2024-08-09 06:40:23 -----  Query completed\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lYBux2de1-XU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}